{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**R^2 Score**\n",
        "\n",
        "R^2 score is calculated on the testing set because it provides an unbiased estimate of how well the model will perform on new, unseen data, which is crucial for model evaluation and selection."
      ],
      "metadata": {
        "id": "v9wM6t_Y6S5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Question 4: Differentiate between generalization, overfitting, and underfitting.\n",
        "\n",
        "- **Generalization**:\n",
        "  - **Definition**: The ability of a machine learning model to perform well on new, unseen data.\n",
        "  - **Significance**: A well-generalized model can make accurate predictions on data it hasn't seen during training.\n",
        "  \n",
        "- **Overfitting**:\n",
        "  - **Definition**: Occurs when a model learns the noise and details in the training data to the extent that it negatively impacts the model's ability to generalize.\n",
        "  - **Significance**: Overfitted models have high accuracy on training data but poor accuracy on new data.\n",
        "\n",
        "- **Underfitting**:\n",
        "  - **Definition**: Occurs when a model is too simple to capture the underlying pattern of the data.\n",
        "  - **Significance**: Underfitted models have poor performance on both training and new data.\n",
        "\n",
        "### Question 6: Study the impact of dataset variation on R^2 score.\n",
        "\n",
        "- **Impact of Dataset Variation**:\n",
        "  - **R^2 Score**: Measures how well the regression model fits the observed data.\n",
        "  - **Impact**:\n",
        "    - High-quality, well-structured datasets typically yield higher \\( R^2 \\) scores.\n",
        "    - Noisy, unstructured datasets may result in lower \\( R^2 \\) scores.\n",
        "    - Large variations in dataset quality can significantly impact \\( R^2 \\) scores.\n",
        "\n",
        "### Question 7: Discuss the strengths and weaknesses of linear and kNN regressions.\n",
        "\n",
        "- **Linear Regression**:\n",
        "  - **Strengths**: Simple to implement and interpret, works well with linearly separable data, provides insights into relationships between variables.\n",
        "  - **Weaknesses**: Assumes a linear relationship between variables, sensitive to outliers, may underperform when the relationship is non-linear.\n",
        "\n",
        "- **k-Nearest Neighbors (kNN) Regression**:\n",
        "  - **Strengths**: Non-parametric, does not assume any underlying data distribution, flexible and can capture complex patterns.\n",
        "  - **Weaknesses**: Computationally expensive, sensitive to the choice of k, does not generalize well to high-dimensional data.\n",
        "\n",
        "### Question 8: Analyze the impact of \\( R^2 \\) on the mean relative error for wave and Boston Housing datasets.\n",
        "\n",
        "- **Wave Dataset**:\n",
        "  - **KNN**:\n",
        "    - \\( R^2 \\) Score: 0.8183\n",
        "    - Mean Relative Error: 0.1345\n",
        "  - **Linear Regression**:\n",
        "    - \\( R^2 \\) Score: 0.6608\n",
        "    - Mean Relative Error: 0.4714\n",
        "\n",
        "- **California Housing Dataset**:\n",
        "  - **KNN**:\n",
        "    - \\( R^2 \\) Score: 0.8206\n",
        "    - Mean Relative Error: 0.2105\n",
        "  - **Linear Regression**:\n",
        "    - \\( R^2 \\) Score: 0.8411\n",
        "    - Mean Relative Error: 0.2360\n",
        "\n",
        "- **Impact of \\( R^2 \\) on Mean Relative Error**: Generally, higher \\( R^2 \\) scores correlate with lower mean relative error, indicating better model performance.\n",
        "\n",
        "**R^2 Score**\n",
        "It ranges from 0 to 1, where 1 indicates that the model perfectly predicts the target variable based on the independent variables.\n",
        "\n",
        "**Mean relative Error**\n",
        "Lower mean relative error indicates better model performance, as it means the model's predictions are closer to the actual values.\n",
        "\n",
        "\n",
        "R^2 and mean relative error are complementary metrics in evaluating the performance of regression models.\n",
        "Higher R^2 scores are generally associated with lower mean relative error, which indicates better model performance in predicting the target variable."
      ],
      "metadata": {
        "id": "JRmkcPSdAkt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install mglearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuqiYn-ipTVX",
        "outputId": "23a7c377-c3d0-45ca-facf-af233714fbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mglearn\n",
            "  Downloading mglearn-0.2.0-py2.py3-none-any.whl (581 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/581.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/581.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m573.4/581.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mglearn) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mglearn) (2.0.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from mglearn) (9.4.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from mglearn) (0.12.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from mglearn) (2.31.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mglearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mglearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mglearn) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mglearn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mglearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.16.0)\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPyt9tyFVfj1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# KNN Using Build-in Dataset\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import mglearn\n",
        "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0)\n",
        "knn_reg= KNeighborsRegressor(n_jobs=-1, n_neighbors=3)\n",
        "knn_reg.fit(X_train, y_train)\n",
        "\n",
        "# to make predictions on X_test\n",
        "prediction_X= knn_reg.predict(X_test)\n",
        "print('the prediction on testing feature is:'+ str(prediction_X))\n",
        "# the ammount of variance in the target vector explained by the model\n",
        "r_square= knn_reg.score(X_test, y_test)\n",
        "print('The R Score is '+ str(r_square))\n",
        "\n",
        "# mean_relative_error = np.mean(np.abs((y_pred - y) / y))\n",
        "# mean_relative_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNEAL3oCVyHW",
        "outputId": "ed2d6bc9-2e51-44f2-a36d-15ce08617d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prediction on testing feature is:[-0.05396539  0.35686046  1.13671923 -1.89415682 -1.13881398 -1.63113382\n",
            "  0.35686046  0.91241374 -0.44680446 -1.13881398]\n",
            "The R Score is 0.8344172446249605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 2:Compute the mean relative error of actual and predicted dependent variable using the following formula. Write the code and output.\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import mglearn\n",
        "\n",
        "X, y= mglearn.datasets.make_wave(n_samples= 40)\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0, test_size= 0.2)\n",
        "\n",
        "\n",
        "lr_reg= LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "lr_reg_score_train=lr_reg.score(X_train, y_train)\n",
        "lr_reg_score_test=lr_reg.score(X_test, y_test)\n",
        "\n",
        "y_pred= lr_reg.predict(X_test)\n",
        "# mean_relative_error = np.mean(np.abs((y_test - X_test) / X_test))\n",
        "mean_relative_error= np.mean(np.abs((y_pred - X_test))/X_test)\n",
        "mean_relative_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GSEwQ3jmdQP",
        "outputId": "7a1be196-86ec-45a1-ad5f-f9a9b9cf7ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2755425970628801"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X, y= mglearn.datasets.load_extended_boston()\n",
        "# print(X.shape)\n",
        "# print(y.shape)\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0, test_size= 0.2)\n",
        "# lr_reg= LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# lr_reg_score= lr_reg.score(X_test, y_test)\n",
        "# lr_reg_score\n",
        "\n"
      ],
      "metadata": {
        "id": "QCdX2EXUt_ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqz2tts4wS9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "X= df[[\"total_rooms\"]]\n",
        "y= df[\"total_bedrooms\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0, test_size= 0.2)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "lr_reg= LinearRegression().fit(X_train, y_train)\n",
        "y_pred= lr_reg.predict(X_test)\n",
        "\n",
        "\n",
        "lr_reg_score_rsquare= lr_reg.score(X_test, y_test)\n",
        "print(lr_reg_score_rsquare)\n",
        "mean_relative_error= np.mean(np.abs((y_pred - y_test)/y_pred))\n",
        "print(mean_relative_error)\n",
        "mse = np.mean((y_pred - y_test)**2)\n",
        "print(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG8Qi8dzuosD",
        "outputId": "8646f2ae-ff58-46ef-b811-3d21756061e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13600, 1)\n",
            "(13600,)\n",
            "(3400, 1)\n",
            "(3400,)\n",
            "0.8411231646860435\n",
            "0.19778964277789\n",
            "26231.403924160844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 3: Compare the linear and kNN regressions on the basis of R^2 and mean relative error for wave and Boston Housing datasets.\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import mglearn\n",
        "\n",
        "\n",
        "def mean_relative_error(y_pred, y_test):\n",
        "  return np.mean(np.abs((y_pred - y_test))/y_test)\n",
        "\n",
        "# KNN Using Build-in Dataset\n",
        "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0, test_size= 0.2)\n",
        "knn_reg= KNeighborsRegressor(n_jobs=-1, n_neighbors=3)\n",
        "knn_reg.fit(X_train, y_train)\n",
        "y_pred= knn_reg.predict(X_test)\n",
        "# to make predictions on X_test\n",
        "prediction_X= knn_reg.predict(X_test)\n",
        "# print('the prediction on testing feature is:'+ str(prediction_X))\n",
        "# the ammount of variance in the target vector explained by the model\n",
        "r_square= knn_reg.score(X_test, y_test)\n",
        "print('The R^2 Score of KNN on wave dataset'+ str(r_square))\n",
        "print('the mean relative error of KNN on wave dataset' + str(mean_relative_error(y_pred, y_test)))\n",
        "\n",
        "# Linear Regression Using Built-in Dataset\n",
        "X, y= mglearn.datasets.make_wave(n_samples= 40)\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0, test_size= 0.2)\n",
        "lr_reg= LinearRegression().fit(X_train, y_train)\n",
        "y_pred= lr_reg.predict(X_test)\n",
        "lr_reg_score_test=lr_reg.score(X_test, y_test)\n",
        "print('the R^2 score of Linear Regression testing wave dataset'+ str(lr_reg_score_test))\n",
        "print('the mean relative error of Linear Regression wave dataset' + str(mean_relative_error(y_pred, y_test)))\n",
        "\n",
        "df= pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "X= df[[\"total_rooms\"]]\n",
        "y= df[\"total_bedrooms\"]\n",
        "\n",
        "\n",
        "# KNN using California Housing Training dataset\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0, test_size= 0.2)\n",
        "knn_reg= KNeighborsRegressor(n_neighbors= 5, n_jobs= -1)\n",
        "knn_reg= knn_reg.fit(X_train, y_train)\n",
        "y_pred= knn_reg.predict(X_test)\n",
        "r_square= knn_reg.score(X_test, y_test)\n",
        "print('The R^2 Score is of KNN on California Housing dataset'+ str(r_square))\n",
        "print('the mean relative error of KNN on California Housing dataset' + str(mean_relative_error(y_pred, y_test)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Linear Regression using California Hosuing Training Dataset\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=0, test_size= 0.2)\n",
        "lr_reg= LinearRegression().fit(X_train, y_train)\n",
        "y_pred= lr_reg.predict(X_test)\n",
        "\n",
        "lr_reg_score_train=lr_reg.score(X_train, y_train)\n",
        "lr_reg_score_test=lr_reg.score(X_test, y_test)\n",
        "print('the R^2 score is of Linear Regression on California Housing dataset'+ str(lr_reg_score_test))\n",
        "print('the mean relative error of of Linear Regression on California Housing dataset' + str(mean_relative_error(y_pred, y_test)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFdwgB432I8l",
        "outputId": "3e853457-1b06-4df6-d0f0-2cd7dd4bd35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The R^2 Score of KNN on wave dataset0.8183022897768604\n",
            "the mean relative error of KNN on wave dataset0.13446818817673806\n",
            "the R^2 score of Linear Regression testing wave dataset0.6607869057739273\n",
            "the mean relative error of Linear Regression wave dataset0.4713975184565494\n",
            "The R^2 Score is of KNN on California Housing dataset0.8205980343355469\n",
            "the mean relative error of KNN on California Housing dataset0.2104500750003855\n",
            "the R^2 score is of Linear Regression on California Housing dataset0.8411231646860435\n",
            "the mean relative error of of Linear Regression on California Housing dataset0.2360237740000491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 5: Analyze the kNN regression with k=1, 3, and 9 for wave and Boston Housing datasets.\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#KNN using Built-in dataset\n",
        "X, y= mglearn.datasets.make_wave(n_samples= 60)\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state= 0, test_size= 0.2)\n",
        "\n",
        "k = [1, 3, 9]\n",
        "for neighbor in k:\n",
        "  knn= KNeighborsRegressor(n_neighbors=neighbor)\n",
        "  knn= knn.fit(X_train, y_train)\n",
        "  y_pred= knn.predict(X_test)\n",
        "  print(f'For Built-in Dataset \"wave\", the value of k is {neighbor} and the predicted output is {np.round(y_pred, 3)}.')\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "\n",
        "#KNN using California housing dataset\n",
        "X= df[[\"total_bedrooms\"]]\n",
        "y= df[\"total_rooms\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state= 42, test_size= 0.2)\n",
        "\n",
        "\n",
        "k= [1, 3, 9]\n",
        "for neighbor in k:\n",
        "  knnh= KNeighborsRegressor(n_neighbors=neighbor)\n",
        "  knnh= knnh.fit(X_train, y_train)\n",
        "  y_pred= knnh.predict(X_test)\n",
        "  print(f'For Built-in Dataset \"California Housing\", the value of k is {neighbor} and the predicted output is {np.round(y_pred, 3)}.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVRj8zAWtMzA",
        "outputId": "8ef8b308-10b4-478e-a74c-6089255e927a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Built-in Dataset \"wave\", the value of k is 1 and the predicted output is [-1.547  0.799 -0.026  0.652  0.731  0.45   0.731 -0.081 -0.752 -0.746\n",
            " -2.374 -0.447].\n",
            "For Built-in Dataset \"wave\", the value of k is 3 and the predicted output is [-1.481  0.708 -0.183  0.706  0.647  0.504  0.647 -0.41  -1.13  -0.423\n",
            " -1.401 -0.41 ].\n",
            "For Built-in Dataset \"wave\", the value of k is 9 and the predicted output is [-1.291  0.878 -0.629  0.449  0.95   0.48   0.95  -0.99  -1.277 -0.661\n",
            " -1.309 -0.99 ].\n",
            "\n",
            "\n",
            "For Built-in Dataset \"California Housing\", the value of k is 1 and the predicted output is [5284. 2644. 3218. ...  199.  299.  247.].\n",
            "For Built-in Dataset \"California Housing\", the value of k is 3 and the predicted output is [5507.    2181.667 3526.333 ...  199.333  330.667  407.333].\n",
            "For Built-in Dataset \"California Housing\", the value of k is 9 and the predicted output is [5029.    2129.111 3504.111 ...  190.667  477.444  369.556].\n"
          ]
        }
      ]
    }
  ]
}